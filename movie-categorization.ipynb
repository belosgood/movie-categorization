{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 02\n",
    "\n",
    "Isabel Osgood & Jen Lee\n",
    "\n",
    "## Experiment Objective\n",
    "\n",
    "Anyone who has seen a romance movie or read a romance novel knows the generic plotline - Girl feels incomplete in life, girl meets boy, world tries to keep boy and girl apart but they overcome and kiss passionately as the screen fades to black. That is when the next genre comes in to film all the dirty details usually kept behind closed doors - pornography. \n",
    "\n",
    "In this project we attempt to tease out the not so subtle differences between romantic comedy plot lines and the plot lines of \"adult\" films. We will be using a dataset collected from IMDB using the key words 'romantic-comedy' and 'adult-film'. All the information used is avaialable using a public API and presents no ethical qualms. Instead of using 'positive or negative' we used genre to classify plots as 'dirty or clean' \n",
    "\n",
    "### Dataset\n",
    "\n",
    "#### TOS and Ethical Considerations\n",
    "Data was taken from IMdb using [IMDbPY](https://imdbpy.github.io/). IMdB's [Conditions](https://www.imdb.com/conditions) specifically says they do not allow the use of \"data mining, robots, screen scraping, or similar data gathering\". Luckily, IMDbPY uses a copy of the IMdb Databases, which can be [used for personal and non-commercial use](https://help.imdb.com/article/imdb/general-information/can-i-use-imdb-data-in-my-software/G5JTRESSHJBBHTGX#) as long as the following statement is included:\n",
    "\n",
    "**Information courtesy of\n",
    "IMDb\n",
    "(http://www.imdb.com).\n",
    "Used with permission.**\n",
    "\n",
    "IMDb is a very popular source to use, so we see no ethical problem with this dataset.\n",
    "\n",
    "#### Sentiment Determination\n",
    "\n",
    "The sentement is coming from the 'plot' descriptions of these movies and videos. These plots are written by users, and come in an array. The first item in the array will be the most highly voted plot synopsis.\n",
    "\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "The necessary Python code to retrieve and store the training examples we will be using to create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb\n",
    "\n",
    "ia = imdb.IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = ['title', 'plot', 'genre'])\n",
    "\n",
    "# Because fetching movies from imdb takes quite some time, we are saving the movies to a csv file. That was there\n",
    "# is never any need to fetch the same movie twice.\n",
    "preloaded_df = pd.read_csv('./data/film-plots-raw.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_results = []\n",
    "# 5579935 - Eva Lovia (actress)\n",
    "star = ia.get_person(5579935)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 3528470 - Dick Bush (director)\n",
    "star = ia.get_person(3528470)\n",
    "a_results += star.data.get('filmography').get('director')\n",
    "\n",
    "# 7531728 - Elsa Jean (actress)\n",
    "star = ia.get_person(7531728)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 2628347 - Kayden Kross (acress and director)\n",
    "star = ia.get_person(2628347)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "a_results += star.data.get('filmography').get('director')\n",
    "\n",
    "# 1279296 - Manual Ferra (actor and director)\n",
    "star = ia.get_person(1279296)\n",
    "a_results += star.data.get('filmography').get('actor')\n",
    "a_results += star.data.get('filmography').get('director')\n",
    "\n",
    "# 4487058 - Dani Daniels (actress)\n",
    "star = ia.get_person(4487058)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 7060064 - Mia Khalifa (actress)\n",
    "star = ia.get_person(7060064)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 1317917 - Storm Daniels (actress, writer, and director)\n",
    "star = ia.get_person(1317917)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "a_results += star.data.get('filmography').get('writer')\n",
    "a_results += star.data.get('filmography').get('director')\n",
    "\n",
    "# 2670531 - Asa Akira (actress)\n",
    "star = ia.get_person(2670531)\n",
    "a_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 1948097 - Johnny Castle (actor)\n",
    "star = ia.get_person(1948097)\n",
    "a_results += star.data.get('filmography').get('actor')\n",
    "\n",
    "# 5822700 - Johnny Rapid (actor)\n",
    "star = ia.get_person(5822700)\n",
    "a_results += star.data.get('filmography').get('actor')\n",
    "\n",
    "# Because a lot of people star and directoy in their own films - lets make this a set to go faster\n",
    "a_results = list(set(a_results))\n",
    "\n",
    "\n",
    "for a in a_results:\n",
    "    # if movie already in raw-csv, no need to fetch\n",
    "    if int(a.movieID) in preloaded_df.index:\n",
    "        df.loc[a.movieID] = preloaded_df.loc[int(a.movieID), :]\n",
    "    else:\n",
    "        movie = ia.get_movie(a.movieID)\n",
    "        \n",
    "        # Weed out anything that isn't an adult-film \n",
    "        genre = None\n",
    "        if movie.data.get('genres') and 'Adult' in movie.data.get('genres'):\n",
    "            genre = 'adult-film'\n",
    "            \n",
    "        plot = None\n",
    "        if (movie.get('plot')):\n",
    "            plot = movie.get('plot')[0]\n",
    "            \n",
    "        df.loc[movie.movieID] = [movie.data.get('title'), plot, genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_results = []\n",
    "r_results += ia.get_top250_movies() # adding the top 250 cause surely some are romantic-comedies\n",
    "r_results += ia.get_bottom100_movies() # honestly probably even more are in the bottom 100\n",
    "# none of these have anywhere close to 1000 results, but just to make sure \n",
    "# we get them all if they're there\n",
    "r_results += ia.get_keyword('romantic-comedy', results=1000)\n",
    "r_results += ia.get_keyword('rom-com', results=1000)\n",
    "r_results += ia.get_keyword('romcom', results=1000)\n",
    "r_results += ia.get_keyword('new-age-rom-com', results=1000)\n",
    "r_results += ia.get_keyword('romantic-comedy-spoof', results=1000)\n",
    "r_results += ia.get_keyword('gay-romcom', results=1000)\n",
    "r_results += ia.get_keyword('bedroom-comedy', results=1000)\n",
    "r_results += ia.get_keyword('sexual-comedy', results=1000)\n",
    "r_results += ia.get_keyword('bromantic-comedy', results=1000)\n",
    "r_results += ia.get_keyword('lesbian-romantic-comedy', results=1000)\n",
    "r_results += ia.get_keyword('cliche', results=1000)\n",
    "\n",
    "# Still don't have enough so lets add by using famous romatic-comedy leads\n",
    "# 0000147 - Colin Firth (actor)\n",
    "star = ia.get_person(int('000147'))\n",
    "r_results += star.data.get('filmography').get('actor')\n",
    "\n",
    "# 0000022 - Clark Gable (actor)\n",
    "star = ia.get_person(int('0000022'))\n",
    "r_results += star.data.get('filmography').get('actor')\n",
    "\n",
    "# 0000158 - Tom Hanks (actor)\n",
    "star = ia.get_person(int('0000158'))\n",
    "r_results += star.data.get('filmography').get('actor')\n",
    "\n",
    "# 0000106 - Drew Barrymore (actress)\n",
    "star = ia.get_person(int('0000106'))\n",
    "r_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 0000658 - Meryl Streep (actress)\n",
    "star = ia.get_person(int('0000658'))\n",
    "r_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 0001191 - Adam Sandler (actor)\n",
    "star = ia.get_person(int('0001191'))\n",
    "r_results += star.data.get('filmography').get('actor')\n",
    "\n",
    "# 1297015 - Emma Stone (actress)\n",
    "star = ia.get_person(int('1297015'))\n",
    "r_results += star.data.get('filmography').get('actress')\n",
    "\n",
    "# 0001188 - Nora Ephron (writer)\n",
    "star = ia.get_person(int('0001188'))\n",
    "r_results += star.data.get('filmography').get('writer')\n",
    "\n",
    "# Make this a set to go faster\n",
    "r_results = list(set(r_results))\n",
    "\n",
    "for r in r_results:\n",
    "    # if movie already in raw-csv, no need to fetch\n",
    "    if int(r.movieID) in preloaded_df.index:\n",
    "        df.loc[r.movieID] = preloaded_df.loc[int(r.movieID), :]\n",
    "    else:\n",
    "        movie = ia.get_movie(r.movieID)\n",
    "        # Make sure no adult-films accidentally fall in here\n",
    "        genre = None\n",
    "        if movie.data.get('genres') and 'Adult' not in movie.data.get('genres') and 'Romance' in movie.data.get('genres') and 'Comedy' in movie.data.get('genres'):\n",
    "            genre = 'romantic-comedy'\n",
    "        \n",
    "        plot = None\n",
    "        if movie.get('plot'):\n",
    "            plot = movie.get('plot')[0]\n",
    "            \n",
    "        df.loc[movie.movieID] = [movie.data.get('title'), plot, genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a 'raw' csv file\n",
    "df.to_csv('./data/film-plots-raw.csv', index=True)\n",
    "\n",
    "# Drop na\n",
    "df = df.dropna()\n",
    "\n",
    "# Save to another csv file\n",
    "df.to_csv('./data/film-plots-most-recent.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958060</th>\n",
       "      <td>Driven</td>\n",
       "      <td>Cop risks his job when he becomes jealously ob...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360984</th>\n",
       "      <td>Couples Fantasies</td>\n",
       "      <td>These couples have hot fantasies.</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376582</th>\n",
       "      <td>Fantasies Come True</td>\n",
       "      <td>Everyone bangs hard and long</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463709</th>\n",
       "      <td>Secrets of the Velvet Ring</td>\n",
       "      <td>Meet Nadia a beautiful and successful woman wi...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934789</th>\n",
       "      <td>Bad Wives</td>\n",
       "      <td>Five steamy cuckolding stories of what's reall...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "958060                       Driven   \n",
       "5360984           Couples Fantasies   \n",
       "3376582         Fantasies Come True   \n",
       "463709   Secrets of the Velvet Ring   \n",
       "934789                    Bad Wives   \n",
       "\n",
       "                                                      plot       genre  \n",
       "958060   Cop risks his job when he becomes jealously ob...  adult-film  \n",
       "5360984                  These couples have hot fantasies.  adult-film  \n",
       "3376582                       Everyone bangs hard and long  adult-film  \n",
       "463709   Meet Nadia a beautiful and successful woman wi...  adult-film  \n",
       "934789   Five steamy cuckolding stories of what's reall...  adult-film  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from same csv file\n",
    "# Start from this block when not loading new data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/film-plots.csv', index_col=0)\n",
    "\n",
    "# Print head to show success\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11181138</th>\n",
       "      <td>Gay of Thrones 6</td>\n",
       "      <td>Johnny Rapid plays a very horny king who summo...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057508</th>\n",
       "      <td>The One</td>\n",
       "      <td>\"Collaging Film\" is a series of shorts dating ...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783958</th>\n",
       "      <td>La La Land</td>\n",
       "      <td>While navigating their careers in Los Angeles,...</td>\n",
       "      <td>romantic-comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080026</th>\n",
       "      <td>Big Wet Breasts 3</td>\n",
       "      <td>Four erotic interludes featuring busty women, ...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867237</th>\n",
       "      <td>All You Can Eat 3</td>\n",
       "      <td>The words 'reverse gangbang' appear on the box...</td>\n",
       "      <td>adult-film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "11181138   Gay of Thrones 6   \n",
       "1057508             The One   \n",
       "3783958          La La Land   \n",
       "7080026   Big Wet Breasts 3   \n",
       "867237    All You Can Eat 3   \n",
       "\n",
       "                                                       plot            genre  \n",
       "11181138  Johnny Rapid plays a very horny king who summo...       adult-film  \n",
       "1057508   \"Collaging Film\" is a series of shorts dating ...       adult-film  \n",
       "3783958   While navigating their careers in Los Angeles,...  romantic-comedy  \n",
       "7080026   Four erotic interludes featuring busty women, ...       adult-film  \n",
       "867237    The words 'reverse gangbang' appear on the box...       adult-film  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_af = df.loc[df['genre'] == 'adult-film']\n",
    "df_rc = df.loc[df['genre'] == 'romantic-comedy']\n",
    "\n",
    "# Modify dataframe so theres the same amount of each film\n",
    "if len(df_af) > len(df_rc):\n",
    "    df_af = df_af.sample(n = len(df_rc), random_state=1234)\n",
    "elif len(df_rc) > len(df_af):\n",
    "    df_rc = df_rc.sample(n = len(df_af), random_state=1234)\n",
    "    \n",
    "df = df_af.append(df_rc)\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(82020)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "# print to show success\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "All of the steps required to clean text data, tokenize the document, and construct a TfidfVectorizer\n",
    "\n",
    "Create proprocesser function to clean plot sumamry text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessor and map classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11181138</th>\n",
       "      <td>Gay of Thrones 6</td>\n",
       "      <td>johnny rapid plays a very horny king who summo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057508</th>\n",
       "      <td>The One</td>\n",
       "      <td>collaging film is a series of shorts dating b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783958</th>\n",
       "      <td>La La Land</td>\n",
       "      <td>while navigating their careers in los angeles ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080026</th>\n",
       "      <td>Big Wet Breasts 3</td>\n",
       "      <td>four erotic interludes featuring busty women t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867237</th>\n",
       "      <td>All You Can Eat 3</td>\n",
       "      <td>the words reverse gangbang appear on the box c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "11181138   Gay of Thrones 6   \n",
       "1057508             The One   \n",
       "3783958          La La Land   \n",
       "7080026   Big Wet Breasts 3   \n",
       "867237    All You Can Eat 3   \n",
       "\n",
       "                                                       plot  genre  \n",
       "11181138  johnny rapid plays a very horny king who summo...      0  \n",
       "1057508    collaging film is a series of shorts dating b...      0  \n",
       "3783958   while navigating their careers in los angeles ...      1  \n",
       "7080026   four erotic interludes featuring busty women t...      0  \n",
       "867237    the words reverse gangbang appear on the box c...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['plot'] = df['plot'].apply(preprocessor)\n",
    "\n",
    "# convert classes (genre) to integers \n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(df['genre']))}\n",
    "class_mapping\n",
    "df['genre'] = df['genre'].map(class_mapping)\n",
    "\n",
    "# 0 - adult-film\n",
    "# 1 - romantic-comedy\n",
    "\n",
    "# Print head to show success\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Train Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.iloc[:, 1].values, df.iloc[:, 2].values\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.3, \n",
    "                     random_state=0, \n",
    "                     stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions required to tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    \n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    \n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    \n",
    "    tokenized = [porter.stem(word) for word in text.split()]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a TfidfVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Optimization and Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search to find the optimal hyperparameters (including choice of stemming algorithm for TfidfVectorizer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1), (3, 3), (1, 4)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2']},\n",
    "              {'vect__ngram_range': [(1, 1), (3, 3), (1, 4)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter], \n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__class_weight': ['balanced', None],\n",
    "               'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07)},\n",
    "              ]\n",
    "\n",
    "\n",
    "sgd_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', SGDClassifier(max_iter=1000, tol=1e-3, loss='log'))])\n",
    "\n",
    "gs_sgd_tfidf = GridSearchCV(sgd_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       ('clf', SGDClassifier(loss='log'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1), (3, 3), (1, 4)],\n",
       "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yoursel...\n",
       "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yourself',\n",
       "                                                'yourselves', 'he', 'him',\n",
       "                                                'his', 'himself', 'she',\n",
       "                                                \"she's\", 'her', 'hers',\n",
       "                                                'herself', 'it', \"it's\", 'its',\n",
       "                                                'itself', ...],\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x7feb2222e170>,\n",
       "                                              <function tokenizer_porter at 0x7feb2222e4d0>]}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__penalty': 'l2', 'vect__ngram_range': (1, 4), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7feb2222e170>} \n",
      "\n",
      "CV Accuracy: 0.850\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s ' % gs_sgd_tfidf.best_params_)\n",
    "print('\\nCV Accuracy: %.3f' % gs_sgd_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.850\n"
     ]
    }
   ],
   "source": [
    "clf = gs_sgd_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The hyperparameters used were chosen either out of convention or because they were the best optimizers for the problem at hand given the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the classifier against entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Using paramaters found in grid search\n",
    "clf = SGDClassifier(loss='log', max_iter=1000, tol=1e-3, penalty='l2')\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "X = vect.transform(X)\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the resulting object to a file that will be used in website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "dest = os.path.join('website', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "    \n",
    "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n",
    "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a standalone Python file that contains all of the steps required to clean your text data, tokenize the document, and construct a TfidfVectorizer named vectorizer.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting website/vectorizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile website/vectorizer.py\n",
    "\n",
    "# create a standalone Python file that contains all of the \n",
    "# steps required to clean your text data, tokenize the document, \n",
    "# and construct a HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "stop = pickle.load(open(\n",
    "                os.path.join(cur_dir, \n",
    "                'pkl_objects', \n",
    "                'stopwords.pkl'), 'rb'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    \n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "# using the parameters you learned tuning the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(lowercase=False,\n",
    "                        ngram_range=(1, 4),\n",
    "                        stop_words=stop,\n",
    "                        tokenizer=tokenizer,\n",
    "                        preprocessor=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Creation and Publishing\n",
    "\n",
    "### Setting up SQLite database for data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Change working directory to ./website\n",
    "import os\n",
    "os.chdir('website')\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('film_plots.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('DROP TABLE IF EXISTS film_plot_db')\n",
    "c.execute('CREATE TABLE film_plot_db (plot TEXT, genre INTEGER, date TEXT)')\n",
    "\n",
    "# insert datafram into sqlite\n",
    "for index, row in df.iterrows():\n",
    "    c.execute(\"INSERT INTO film_plot_db (plot, genre, date) VALUES (?, ?, DATETIME('now'))\", (row['plot'], row['genre']))\n",
    "    \n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# Change directory back\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website URL\n",
    "\n",
    "http://kyjennm.pythonanywhere.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
